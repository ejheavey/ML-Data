import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

########################################################################
#############################################
#####################
########

x_uniform = 3.5*np.random.random((100, 128))
x_normal = np.random.normal(size = (100,128))
x_poisson = np.random.poisson(lam = 1., size = (100, 128))

x_all = np.vstack((x_uniform, x_normal, x_poisson))

y_uniform = np.array(np.zeros(shape = (x_uniform.shape[0],1)) - 1)  # Label -1
y_normal = np.array(np.zeros(shape = (x_normal.shape[0],1)) + 1)       # Label 1
y_poisson = np.array(np.zeros(shape = (x_poisson.shape[0],1)))# Label 0

y_all = np.vstack((y_uniform, y_normal, y_poisson)).astype('int32')


class perceptron(object):
    def __init__(self, learning_rate = 0.01, num_itrs = 15):
        self.learning_rate = learning_rate
        self.num_itrs = num_itrs
        
    def fit_model(self, input_data, labels_):
        self.weights_ = np.zeros(shape = (1,input_data.shape[1]+1))
        self.errors_ = []
        for _ in range(self.num_itrs):
            errs = 0
            for x, targ in zip(input_data, labels_):
                update = self.learning_rate*(targ - self.predict(x))
                self.weights_[0,1:] += update*x
                self.weights_[0,0] += update
                errs += int(update != 0.)
            self.errors_.append(errs)
        return self

    def net_input(self, input_data):
        return np.dot(input_data, self.weights_[0,1:]) + self.weights_[0,0]

    def predict(self, input_data):
        preds_ = []
        for val in np.nditer(self.net_input(input_data)):
            if val > -1:
                preds_.append(1)
            elif val <= -6:
                preds_.append(-1)
            else: preds_.append(0)
        return preds_


p_multi = perceptron(learning_rate = 0.01, num_itrs = 100)
p_multi.fit_model(x_all, y_all)

fit_vals = p_multi.net_input(x_all)
percent_errs = np.array(p_multi.errors_).reshape((len(p_multi.errors_),1))/fit_vals.shape[0]*100
acc_ = 100*np.ones(shape = (percent_errs.shape[0],1)) - percent_errs


plt.figure()
plt.plot(np.arange(1, percent_errs.shape[0] + 1), percent_errs, label = 'Error')
plt.plot(np.arange(1, acc_.shape[0]+1), acc_, label = 'Accuracy')
plt.xlabel('Epochs'), plt.ylabel('Performance, %')
plt.title('Perceptron performance: Classifying 3 random distribution types\n where class labels are normal dist = 1, uniform = -1, Poisson = 0')
plt.legend(), plt.show()

plt.figure()
plt.hist(fit_vals, bins = fit_vals.shape[0], cumulative = True, color = 'blue', alpha = 0.4, label = 'Total')
plt.hist(fit_vals[:100], bins = 100, cumulative = True, color = 'red', label = 'Uniform')
plt.hist(fit_vals[200:300], bins = 100, cumulative = True, color = 'blue', label = 'Poisson')
plt.hist(fit_vals[100:200], bins = 100, cumulative = True, color = 'green', label = 'Normal')
plt.legend()

########################################################################
#############################################
#####################
########
from matplotlib.colors import ListedColormap

markers = ('x', 'o','s')
colors = ('red','blue', 'green')

x1 = 4*np.random.random(size = (100, 128))
x2 = np.random.normal(size = (100, 128))
x3 = np.random.poisson(size = (100, 128))

unifit = p_multi.net_input(x1)
normfit = p_multi.net_input(x2)
poisfit = p_multi.net_input(x3)


plt.figure()
plt.hist(unifit, bins = unifit.shape[0], color = colors[0], label = 'Uniform dist.')
plt.hist(poisfit, bins = poisfit.shape[0], color = colors[1], label = 'Poisson dist.')
plt.hist(normfit, bins = normfit.shape[0], color = colors[2], label = 'Normal dist.')
plt.xlabel('Weights generated'), plt.ylabel('Counts')
plt.title('Histogram of network weights generated by 3 distribution types in multiclass classification,\n where class labels are normal dist. = 1, uniform = -1, Poisson = 0')
plt.legend()
plt.show()

plt.figure()
plt.hist(unifit, bins = unifit.shape[0], cumulative = True, color = colors[0], label = 'Uniform dist.')
plt.hist(poisfit, bins = poisfit.shape[0], cumulative = True, color = colors[1], label = 'Poisson dist.')
plt.hist(normfit, bins = normfit.shape[0], cumulative = True, color = colors[2], label = 'Normal dist.')
plt.xlabel('Weights generated'), plt.ylabel('Number of sample sequences')
plt.title('Cumulative distribution of weights generated by 3 distribution types in\n multiclass classification with labels normal dist. = 1, uniform = -1, Poisson = 0')
plt.legend()
plt.show()




out_ = p_multi.net_input(x_all)
b = y_all - out_

c = np.zeros(shape=y_all.shape)

for i in range(x_all.shape[0]):
    c[i] = b[i].sum()/len(b[i])

plt.figure(), plt.hist(c, bins = len(c))







